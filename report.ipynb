{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_train import *\n",
    "from model.SimpleANN import *\n",
    "import adversary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment was run two models to see advantage of maximizing lipschitz margin against adversary attacks (for this case was tested against gaussian noise)<br>\n",
    "Both models have the same structure -- simply 3 fully connected layers with ReLu as activation.<br>\n",
    "The first network was optimizing cross etropy loss function while the second model was optiziming cross entropy - margin_rate * margin loss.<br> The margin loss is defined next:<br>\n",
    "$$\\vec{y} = softmax(F(\\vec{x}))$$\n",
    "$$\\mathcal{L}_{lipschitz\\ margin} = \\frac{1}{|\\mathcal{C}|} \\sum_{\\vec{y} \\in \\mathcal{C}}(max(\\vec{y}) - max(\\vec{y}_{/{max(\\vec{y})})}) : \\mathcal{C} = \\{\\vec{y_i} : argmax(\\vec{y_i}) = argmax(\\vec{\\hat{y_i}})\\}$$\n",
    "In another words, munis sum of differences first 2 choices of network, taking to account only examples correctly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 784\n",
    "y_dim = 10\n",
    "trained_marginless = 'trained_models/margin=0/model.ckpt'\n",
    "trained_margin = 'trained_models/margin=1/model.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training for both models with equal hyperparameters<br>\n",
    "$\\lambda = 10^{-4}$<br>\n",
    "$batch\\_size = 64$<br>\n",
    "$steps = 200\\ 000$<br>\n",
    "For model including margin:<br>\n",
    "$margin\\_rate = 1.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "margin_statistics, marginless_statistics = train_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load models trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    model_marginless = SimpleANN(n_dim=n_dim, y_dim=y_dim, margin_rate=0.0, source=trained_marginless)\n",
    "with tf.Graph().as_default():\n",
    "    model_margin = SimpleANN(n_dim=n_dim, y_dim=y_dim, margin_rate=1.0, source=trained_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel(\"Accuracy, %\")\n",
    "plt.xlabel(\"iteration, k\")\n",
    "plt.xscale('log')\n",
    "plt.plot(np.array(marginless_statistics[2]) / 1000, np.array(marginless_statistics[0]) * 100, label=\"w/out margin\")\n",
    "plt.plot(np.array(margin_statistics[2]) / 1000, np.array(margin_statistics[0]) * 100, label=\"w/ margin\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"iteration, k\")\n",
    "plt.xscale('log')\n",
    "plt.plot(np.array(marginless_statistics[2]) / 1000, np.array(marginless_statistics[1]), label=\"w/out margin\")\n",
    "plt.plot(np.array(margin_statistics[2]) / 1000, np.array(margin_statistics[1]), label=\"w/ margin\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of trained models with small test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary.test(model_marginless, dataset=dataset, batch_size=1024, noise=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary.test(model_margin, dataset=dataset, batch_size=1024, noise=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run pairwise test with different noise level (from 0 to 1, complete random image).\n",
    "Plot below shows accuracy of the model on images with given noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = adversary.pair_test(model_margin, model_marginless, dataset, 2**10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depends on hyperparameters, the model with margin shows from no improvement against gaussian noise to up 40% improvements. Was noticed examples where with noise of 20% simple model performed with 40% accuracy while model trained with margin still performed with accuracy >95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot difference graph\n",
    "diff = (np.array(results[0]) - np.array(results[1])) / np.array(results[0])\n",
    "plt.xlabel(\"gaussian noise\")\n",
    "plt.ylabel(\"Margin - marginless. accuracy %\")\n",
    "plt.plot(np.arange(0.0, 1.0, 0.01), diff, label=\"margin accuracy dominance\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
